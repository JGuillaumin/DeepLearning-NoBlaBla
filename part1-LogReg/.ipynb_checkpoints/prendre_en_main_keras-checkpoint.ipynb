{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure d'un script/notebook simple avec Keras\n",
    "\n",
    "-------------------------------\n",
    "-------------------------------\n",
    "- Charger les données\n",
    "- Traiter les données (augmentation ? réduction ?)\n",
    "- Gérer les labels (one-hot encoding)\n",
    "- Découpage train/test\n",
    "-------------------------------\n",
    "-------------------------------\n",
    "- Construire le modèle \n",
    "- Choisir la fonction de coût, des métriques, un algorithme d'optimisation \n",
    "- Compiler le modèle \n",
    "- Configurer l'entrainement (`batch_size`, `nb_epoch`, ...)\n",
    "- Lancer l'entraînement \n",
    "-------------------------------\n",
    "-------------------------------\n",
    "- Lancer l'inférence sur les nouvelles données à labeliser \n",
    "- [Générer le fichier .csv de résultats à envoyer sur Kaggle] \n",
    "-------------------------------\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les données : Digit-Recognizer de Kaggle \n",
    "\n",
    "Reconnaissance de caractères manuscrits (0 à 9)\n",
    "\n",
    "- Application aux chèques bancaires \n",
    "- Yann LeCun a créé le modèle LeNet-5 dans les années 90 sur ce type de problème ! \n",
    "- Benchmark en Deep Learning\n",
    "\n",
    "Données déjà préparées : \n",
    "- découpage train/test \n",
    "- normalisation des données (preprocessing) \n",
    "\n",
    "Reste à faire : `one-hot encoding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = np.load('../data/digit-recognizer/X_train.npy')\n",
    "X_test = np.load('../data/digit-recognizer/X_test.npy')\n",
    "\n",
    "y_train = np.load('../data/digit-recognizer/y_train.npy')\n",
    "y_test = np.load('../data/digit-recognizer/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"X_train shape : {}\".format(X_train.shape))\n",
    "print(\"X_test shape : {}\".format(X_test.shape))\n",
    "print(\"y_train shape : {}\".format(y_train.shape))\n",
    "print(\"y_test shape : {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Afficher quelques exemples \n",
    "for i in range(9):\n",
    "    plt.subplot(331+i)\n",
    "    #Les images sont sous forme de vecteurs, de taille 784=28x28\n",
    "    plt.imshow(X_train[i].reshape(28,28), cmap=cm.binary)\n",
    "plt.show()\n",
    "print(y_train[:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Prendre en main Keras : régression logistique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 API pour construire un modèle avec Keras \n",
    "- **Sequential**\n",
    "    - Empiler les couches, 1 entrée et 1 sortie \n",
    "- **Functional**\n",
    "    - Plusieurs entrées et sorties ! \n",
    " \n",
    "Ce soir : `Sequential` uniquement !  \n",
    " \n",
    "    \n",
    "### Première étape :  construire le modèle\n",
    "\n",
    "Caisse à outils : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(filename='../ressources/regression_logistique.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modèle non profond (aucune couche cachée)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#On charge l'API voulue\n",
    "from keras.models import Sequential\n",
    "\n",
    "#et les couches nécessaires \n",
    "from keras.layers import Dense, Activation\n",
    "\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## La couche `Dense`\n",
    "\n",
    "Couche 'full-connected' classique \n",
    "\n",
    "```python\n",
    "keras.layers.core.Dense(output_dim, \n",
    "                        init='glorot_uniform',\n",
    "                        activation=None,\n",
    "                        weights=None,\n",
    "                        W_regularizer=None,\n",
    "                        b_regularizer=None,\n",
    "                        activity_regularizer=None,\n",
    "                        W_constraint=None,\n",
    "                        b_constraint=None,\n",
    "                        bias=True,\n",
    "                        input_dim=None)\n",
    "```\n",
    "\n",
    "- **output_dim**: int > 0.\n",
    "- **init**: nom de la règle d'initialisation des poids. (uniform, normal, identity, orthogonal, zero, one, glorot_normal, glorot_uniform, he_normal, he_uniform, ...)\n",
    "- **activation**: nom de la fonction d'activation (pour l'instant `softmax`)\n",
    "- **W_regularizer**: instance d'un `WeightRegularizer` (eg. L1 or L2 regularization), appliqué aux poids de la matrice.\n",
    "- **b_regularizer**: instance d'un `WeightRegularizer`, appliqué au vecteur de biais.\n",
    "- **input_dim**: dimension du vecteur d'entrée, à spécifier uniquement pour la première couche. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "\n",
    "Comment ajouter la régularisation L2 ? \n",
    "\n",
    "\n",
    "```python \n",
    "from keras.regularizers import l2\n",
    "model.add(Dense(64, input_dim=64, W_regularizer=l2(0.01)))\n",
    "```\n",
    "\n",
    "\n",
    "(ici uniquement sur la matrice W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# On peut ensuite construire le modèle \n",
    "# En ajoutant les couches dans 'model'\n",
    "model = Sequential()\n",
    "\n",
    "# Dans la première couche, il faut toujours spécifier la dimension d'entrée ! Ici un vecteur de taille 784\n",
    "model.add(Dense(10, input_dim=784, W_regularizer=l2(0.01)))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seconde étape : fonction de coût ? métriques ? algorithme d'optimisation ?\n",
    "\n",
    "Métriques :\n",
    "    - uniquement indicatives \n",
    "    - calculées sur chaque batch et pour les données de test (ou validation_data dans Keras)\n",
    "\n",
    "Fonction de coût :\n",
    "    - fonction à minimiser \n",
    "    - Cas de la classification multi-classes  : `categorical_crossentropy`\n",
    "\n",
    "\n",
    "Pour aller plus loin: écrire ses propres métriques !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Il existe beaucoup de méthodes d'optimisation : ce soir uniquement SGD \n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# choix du `learning rate` (il existe d'autres paramètres pour SGD)\n",
    "sgd = SGD(lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troisième étape : entraînement\n",
    "\n",
    "On indique : \n",
    "- les données d'entraînement (X_train,y_train)\n",
    "- la taille des batch \n",
    "- le nombre d'epoch\n",
    "- les données de test (ou validation) \n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=32, nb_epoch=10, verbose=1,\n",
    "          validation_split=0.0, validation_data=None,\n",
    "          shuffle=True,\n",
    "          class_weight=None, sample_weight=None,\n",
    "          initial_epoch=0,\n",
    "          callbacks=None)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encoding à ne pas oublier !\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 30\n",
    "\n",
    "history = model.fit(X_train, to_categorical(y_train,nb_classes=10),\n",
    "                    batch_size = batch_size,\n",
    "                    nb_epoch = nb_epoch,\n",
    "                    verbose=1,\n",
    "                    validation_data=(X_test, to_categorical(y_test,nb_classes=10)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy %')\n",
    "plt.xlabel('Training iterations')\n",
    "plt.legend(['Testing'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer le modèle à de nouvelles données \n",
    "\n",
    "**3 façon de lancer l'inférence :** \n",
    "\n",
    "```python\n",
    "# Calcule l'erreur et les métriques \n",
    "model.evaluate(self, x, y, batch_size=32, verbose=1)\n",
    "\n",
    "# Renvoie pour chaque exemple un vecteur de probabilité \n",
    "model.predict(self, x, batch_size=32, verbose=0)\n",
    "\n",
    "# Renvoie pour chaque exemple la classe prédite \n",
    "model.predict_classes(self, x, batch_size=32, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = np.load('../data/digit-recognizer/test_data.npy')\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(test_data,batch_size=128,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Afficher quelques exemples \n",
    "for i in range(9):\n",
    "    plt.subplot(331+i)\n",
    "    #Les images sont sous forme de vecteurs, de taille 784=28x28\n",
    "    plt.imshow(test_data[i].reshape(28,28), cmap=cm.binary)\n",
    "plt.show()\n",
    "print(predictions[:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A faire chez soi : envoyerrésultats sur Kaggle\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({\"ImageId\": list(range(1,len(test_data)+1)), \n",
    "              \"Label\": predictions}).to_csv('DIGIT-RECOGNIZER-submission.csv', index=False,header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enregistrer son modèle\n",
    "\n",
    "#### Uniquement l'architecture du modèle dans un fichier json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_string = model.to_json()\n",
    "\n",
    "with open('model.json', 'w') as outfile:\n",
    "    json.dump(json_string, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cat model.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pour instacier un modèle depuis un fichier JSON : \n",
    "from keras.models import model_from_json\n",
    "\n",
    "with open(\"model.json\") as json_file:\n",
    "    json_string = json.load(json_file)\n",
    "\n",
    "model2 = model_from_json(json_string)\n",
    "#Le modèle model2 a la même architecture, mais des poids différents (poids initiaux aléatoires)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uniquement les poids entraînés dans un fichier hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2.load_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Achitecture + poids entraînés dans un fichier hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model3 = load_model('model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
